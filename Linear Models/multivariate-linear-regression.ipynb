{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5845248,"sourceType":"datasetVersion","datasetId":3360797}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-26T09:18:35.515185Z","iopub.execute_input":"2024-02-26T09:18:35.515681Z","iopub.status.idle":"2024-02-26T09:18:35.521692Z","shell.execute_reply.started":"2024-02-26T09:18:35.515636Z","shell.execute_reply":"2024-02-26T09:18:35.520012Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset into a dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/salary-prediction-data-simple-linear-regression/Salary Data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-02-26T09:18:35.525094Z","iopub.execute_input":"2024-02-26T09:18:35.525661Z","iopub.status.idle":"2024-02-26T09:18:35.559216Z","shell.execute_reply.started":"2024-02-26T09:18:35.525612Z","shell.execute_reply":"2024-02-26T09:18:35.557788Z"},"trusted":true},"execution_count":166,"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"    YearsExperience    Salary\n0               1.1   39343.0\n1               1.3   46205.0\n2               1.5   37731.0\n3               2.0   43525.0\n4               2.2   39891.0\n5               2.9   56642.0\n6               3.0   60150.0\n7               3.2   54445.0\n8               3.2   64445.0\n9               3.7   57189.0\n10              3.9   63218.0\n11              4.0   55794.0\n12              4.0   56957.0\n13              4.1   57081.0\n14              4.5   61111.0\n15              4.9   67938.0\n16              5.1   66029.0\n17              5.3   83088.0\n18              5.9   81363.0\n19              6.0   93940.0\n20              6.8   91738.0\n21              7.1   98273.0\n22              7.9  101302.0\n23              8.2  113812.0\n24              8.7  109431.0\n25              9.0  105582.0\n26              9.5  116969.0\n27              9.6  112635.0\n28             10.3  122391.0\n29             10.5  121872.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearsExperience</th>\n      <th>Salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.1</td>\n      <td>39343.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.3</td>\n      <td>46205.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.5</td>\n      <td>37731.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>43525.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.2</td>\n      <td>39891.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.9</td>\n      <td>56642.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.0</td>\n      <td>60150.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3.2</td>\n      <td>54445.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.2</td>\n      <td>64445.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.7</td>\n      <td>57189.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3.9</td>\n      <td>63218.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.0</td>\n      <td>55794.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4.0</td>\n      <td>56957.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4.1</td>\n      <td>57081.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4.5</td>\n      <td>61111.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4.9</td>\n      <td>67938.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>5.1</td>\n      <td>66029.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5.3</td>\n      <td>83088.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5.9</td>\n      <td>81363.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>6.0</td>\n      <td>93940.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>6.8</td>\n      <td>91738.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>7.1</td>\n      <td>98273.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>7.9</td>\n      <td>101302.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>8.2</td>\n      <td>113812.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>8.7</td>\n      <td>109431.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>9.0</td>\n      <td>105582.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>9.5</td>\n      <td>116969.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>9.6</td>\n      <td>112635.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>10.3</td>\n      <td>122391.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>10.5</td>\n      <td>121872.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preaparing the training and test dataset","metadata":{}},{"cell_type":"code","source":"data = np.asarray(df) #Converting the dataset into a numpy array\n\n\ny_train = data[0:14,-1] #All row last column \nx_train = data[0:14,0:1] #All row first two columns\n\ny_test = data[15:,-1] #All row last column \nx_test = data[15:,0:1] #All row first two columns\n\nm,c = x_train.shape\nprint('Total row: {0}\\nColumn: {1}'.format(m,c))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T09:18:35.561317Z","iopub.execute_input":"2024-02-26T09:18:35.562156Z","iopub.status.idle":"2024-02-26T09:18:35.572027Z","shell.execute_reply.started":"2024-02-26T09:18:35.562101Z","shell.execute_reply":"2024-02-26T09:18:35.570638Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stdout","text":"Total row: 14\nColumn: 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Linear Regression","metadata":{}},{"cell_type":"code","source":"class LinearRegression:\n    \"\"\"\n    Simple linear regression model that uses gradient descent to fit the model to the data.\n    \n    Attributes:\n    x_train (ndarray): Training features, shape (n_samples, n_features).\n    y_train (ndarray): Training labels, shape (n_samples,).\n    iteration (int): Number of iterations for the gradient descent.\n    alpha (float): Learning rate for gradient descent.\n    \"\"\"\n    \n    def __init__(self, x_train, y_train, iteration, alpha):\n        \"\"\"\n        Initializes the LinearRegression model with training data, number of iterations, and learning rate.\n        \n        Parameters:\n        x_train (ndarray): Training features.\n        y_train (ndarray): Training labels.\n        iteration (int): Number of iterations for the gradient descent.\n        alpha (float): Learning rate.\n        \"\"\"\n        self.x_train = x_train\n        self.y_train = y_train\n        self.iteration = iteration\n        self.alpha = alpha\n        \n    def compute_gradient(self, y_predicted):\n        \"\"\"\n        Computes the gradients of the cost function with respect to the model parameters.\n        \n        Parameters:\n        y_predicted (ndarray): Predicted labels based on the current model parameters.\n        \n        Returns:\n        tuple: The gradient with respect to weights (dw) and the gradient with respect to bias (db).\n        \"\"\"\n        m = self.x_train.shape[0]\n        dw = (1/m) * np.dot(self.x_train.T, (y_predicted - self.y_train))\n        db = (1/m) * np.sum(y_predicted - self.y_train)\n        return dw, db\n\n    def compute_cost(self, y_predicted):\n        \"\"\"\n        Computes the cost function for the linear regression model.\n        \n        Parameters:\n        y_predicted (ndarray): Predictions made by the model.\n        \n        Returns:\n        float: The cost associated with the current model parameters.\n        \"\"\"\n        m = self.y_train.size\n        J = np.sum((y_predicted - self.y_train) ** 2) / (2 * m)\n        return J\n\n    def gradient_descend(self):\n        \"\"\"\n        Performs gradient descent to optimize the model parameters.\n        \n        Returns:\n        ndarray: The optimized weights.\n        float: The optimized bias.\n        list: History of the cost function values.\n        list: History of the weights.\n        list: History of the biases.\n        \"\"\"\n        m, c = self.x_train.shape\n        W = np.zeros(c)\n        b = 0\n\n        J_history = []\n        W_history = []\n        B_history = []\n\n        for i in range(self.iteration):\n            y_predicted = np.dot(self.x_train, W) + b\n            J = self.compute_cost(y_predicted)\n            dw, db = self.compute_gradient(y_predicted)\n\n            W -= self.alpha * dw\n            b -= self.alpha * db\n\n            J_history.append(J)\n            W_history.append(W)\n            B_history.append(b)\n\n        return W, b, J_history, W_history, B_history\n    \n    def predict(self, x_test):\n        \"\"\"\n        Makes predictions using the linear regression model.\n        \n        Parameters:\n        x_test (ndarray): Test features.\n        \n        Returns:\n        ndarray: Predictions for the test data.\n        \"\"\"\n        W, b, _, _, _ = self.gradient_descend()\n        return np.dot(x_test, W) + b\n    \n    def evaluate(self, y_predicted, y_test):\n        \"\"\"\n        Evaluates the model using mean squared error.\n        \n        Parameters:\n        y_predicted (ndarray): Predictions made by the model.\n        y_test (ndarray): Actual labels.\n        \n        Returns:\n        float: Mean squared error of the predictions.\n        \"\"\"\n        return np.mean((y_predicted - y_test) ** 2)\n    \n    def r_squared(self, y_predicted, y_test):\n        \"\"\"\n        Calculates the coefficient of determination, R^2, of the prediction.\n        \n        Parameters:\n        y_predicted (ndarray): Predictions made by the model.\n        y_test (ndarray): Actual labels.\n        \n        Returns:\n        float: The R^2 score.\n        \"\"\"\n        ss_res = np.sum((y_test - y_predicted) ** 2)\n        ss_tot = np.sum((y_test - np.mean(y_test)) ** 2)\n        return 1 - (ss_res / ss_tot)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T09:27:50.153216Z","iopub.execute_input":"2024-02-26T09:27:50.153729Z","iopub.status.idle":"2024-02-26T09:27:50.171466Z","shell.execute_reply.started":"2024-02-26T09:27:50.153686Z","shell.execute_reply":"2024-02-26T09:27:50.170032Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"code","source":"lr = linearregression(x_train,y_train,1000,.01 )\nW,B,J_history,W_history,B_history = lr.gradient_descend()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T09:27:58.598106Z","iopub.execute_input":"2024-02-26T09:27:58.598586Z","iopub.status.idle":"2024-02-26T09:27:58.653506Z","shell.execute_reply.started":"2024-02-26T09:27:58.598550Z","shell.execute_reply":"2024-02-26T09:27:58.652261Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"y_predicted  = lr.predict(x_test)\nlr.evaluate(y_predicted,y_test)\nlr.r_squared(y_predicted,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T09:28:01.203102Z","iopub.execute_input":"2024-02-26T09:28:01.203583Z","iopub.status.idle":"2024-02-26T09:28:01.263345Z","shell.execute_reply.started":"2024-02-26T09:28:01.203539Z","shell.execute_reply":"2024-02-26T09:28:01.261800Z"},"trusted":true},"execution_count":189,"outputs":[{"execution_count":189,"output_type":"execute_result","data":{"text/plain":"0.8901383345269578"},"metadata":{}}]}]}